{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtKRoY09TpDu57MlOvLnRn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["We can utilize partition for sorting as well, which leads to the **QuickSort** algorithm. In QuickSort, we first partition the array (using a random pivot), and then recursively sort BOTH the left subarray and the right subarray."],"metadata":{"id":"UDii-nF9acyU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_tG2p2QT8W3","executionInfo":{"status":"ok","timestamp":1752637125240,"user_tz":-360,"elapsed":7,"user":{"displayName":"Mr. Sajed Imtenanul Haque","userId":"08637452032066901971"}}},"outputs":[],"source":["# QuickSort pseudocode\n","def quickSort (lst, left = 0, right = len (lst) - 1):\n","  if left >= right:   # if the subarray has length <= 1, then it is already sorted\n","    return\n","  pidx = random.randint (left, right)   # choose pivot index randomly\n","  p = partition2 (lst, pidx, left, right)   # partition around the chosen pivot\n","  quickSort (lst, left, p - 1)          # recursively sort left subarray\n","  quickSort (lst, p + 1, right)         # recursively sort right subarray"]},{"cell_type":"code","source":["import random\n","\n","def partition2 (lst, pidx, left = 0, right = \"DUMMY\"):\n","  if right == \"DUMMY\":\n","    right = len (lst) - 1\n","  lst[pidx], lst[right] = lst[right], lst[pidx]\n","  pidx = right\n","\n","  i = left - 1\n","  for j in range (left, right):\n","    if lst[j] <= lst[pidx]:\n","      lst[j], lst[i + 1] = lst[i + 1], lst[j]\n","      i += 1\n","  lst[pidx], lst[i + 1] = lst[i + 1], lst[pidx]\n","  return i + 1\n","\n","def quickSort (lst, left = 0, right = \"DUMMY\"):\n","  if right == \"DUMMY\":\n","    right = len (lst) - 1\n","  if left >= right:\n","    return\n","  pidx = random.randint (left, right)\n","  p = partition2 (lst, pidx, left, right)\n","  #print (lst, lst[p])\n","  quickSort (lst, left, p - 1)\n","  quickSort (lst, p + 1, right)\n","\n","lst = [3,2,8,9,15,16,-10,13,0]\n","print (lst)\n","quickSort (lst)\n","print (lst)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Hd_rdhYb6xT","executionInfo":{"status":"ok","timestamp":1752639488701,"user_tz":-360,"elapsed":20,"user":{"displayName":"Mr. Sajed Imtenanul Haque","userId":"08637452032066901971"}},"outputId":"8f4ba83a-3427-4b58-d1d1-181f231144df"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 2, 8, 9, 15, 16, -10, 13, 0]\n","[-10, 0, 2, 3, 8, 9, 13, 15, 16]\n"]}]},{"cell_type":"code","source":["lst = [3,2,8,9,15,16,-10,13,0]\n","\n","lst2 = sorted (lst) # out-of-place sorting\n","print (lst)\n","print (lst2)\n","\n","lst.sort ()     # in-place sorting\n","print (lst)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2R7RR-1dGGq","executionInfo":{"status":"ok","timestamp":1752639521917,"user_tz":-360,"elapsed":14,"user":{"displayName":"Mr. Sajed Imtenanul Haque","userId":"08637452032066901971"}},"outputId":"8ca1b533-a264-4b71-d8b7-e0e1375f65a9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 2, 8, 9, 15, 16, -10, 13, 0]\n","[-10, 0, 2, 3, 8, 9, 13, 15, 16]\n","[-10, 0, 2, 3, 8, 9, 13, 15, 16]\n"]}]},{"cell_type":"markdown","source":["Runtime Analysis of QuickSort\n","\n","Worst-Case Runtime: $\\Theta (n^2)$ just like QuickSelect, arising when the selected pivot is always the smallest/largest element in the subarray, resulting in $n - 1$ elements in one subarray.\n","\n","Best-Case Runtime: $\\Theta (n\\log n)$, which arises when the two subarrays have roughly equal number of elements, in which case the time complexity would be identical to MergeSort (which also splits into equal halves, and performs a $\\Theta (n)$ operation, Merge, instead of Partition)\n","\n","Average-Case Runtime: We can extend the argument for QuickSelect to show that the average-case is the same as the best-case, which is $\\Theta (n \\log n)$."],"metadata":{"id":"5g5Eibxcdb_K"}},{"cell_type":"markdown","source":["Why would we ever use QuickSort over MergeSort? Two reasons:\n","\n","1.  The space complexity for QuickSort is much better. Partition does not require extra space, whereas Merge requires $\\Theta (n)$ additional space. QuickSort, in the way we wrote it, requires $\\Theta (n)$ space in the worst-case as well (from recursion depth), but the average-case space complexity is $\\Theta (\\log n)$.\n","\n","[OPTIONAL] Using tail call elimination and by modifying QuickSort to recursively sort the smaller subarray first, the worst-case space complexity can be improved to $\\Theta (\\log n)$.\n","\n","2.  In practice, QuickSort is just much faster than any of the sorting algorithms we covered in this course and will cover, including MergeSort.\n","\n","In general, for this course, if we want to sort a general array, and we only care about time complexity, MergeSort is the best choice. If we care about both time and space, then QuickSort is the best choice. If we know or should expect that our array is nearly sorted, then InsertionSort is the best choice.\n","\n","If we care about stability, then do NOT use QuickSort. QuickSort is unstable, but the other three are stable. We will discuss stability later.\n","\n","BubbleSort is still garbage."],"metadata":{"id":"jCMxrELqhqPQ"}},{"cell_type":"markdown","source":["BubbleSort, InsertionSort, MergeSort, and QuickSort are all **comparison-based** sorting algorithms. This means that they work for ALL kinds of data, as long as the data elements can be compared. But there is one disadvantage of comparison-based algorithms, which is that there may be a limit to how good the worst-case runtime can be."],"metadata":{"id":"4HT8RCw1kdWA"}},{"cell_type":"markdown","source":["Let's assume we have elements where the only way to gain information about the sorted order is by comparing elements.\n","\n","If I have an array of two elements, [a, b]\n","\n","How many comparisons do I need to guarantee sorting? One.\n","\n","If I have an array of three elements, [a, b, c]\n","\n","How many comparisons do I need to guarantee sorting?\n","\n","Can I guarantee sorting after only one comparison? No.\n","\n","Can I guarantee sorting after only two comparisons? No.\n","\n","Each comparison returns either True or False.\n","\n","If we perform two comparisons, how many possible results can I get? Four: True-True, True-False, False-True, and False-False.\n","\n","With three elements, how many possible orderings can we get?\n","- a, b, c\n","- a, c, b\n","- b, a, c\n","- b, c, a\n","- c, a, b\n","- c, b, a\n","\n","Can we extend this idea to larger arrays?\n","\n","If we perform t comparisons, how many possible results can we get? $2^t$ [each comparison independently has 2 possibilities]\n","\n","If we have an array of size $n$, how many possible orderings are there? First element has $n$ possibilities, Second element has $n-1$, Third element has $n-2$ possibilities, etc, which leads to $n \\times (n - 1) \\times (n - 2) \\times \\cdots \\times 2 \\times 1 = n!$\n","\n","To guarantee sorting the array after $t$ comparisons, we must have $2^t >= n!$, which means $t >= \\log_2 (n!)$, which is in $\\Omega (n \\log n)$.\n","\n","In other words, every comparison-based sorting algorithm must perform $\\Omega (n \\log n)$ comparisons in the worst-case, i.e., the worst-case runtime can never be strictly better than $n \\log n$.\n","\n","Therefore, MergeSort is optimal, with respect to worst-case runtime.\n","\n","The argument can be extended to the average-case, which must also be in $\\Omega (n \\log n)$, so both MergeSort and QuickSort are optimal with respect to average-case runtime."],"metadata":{"id":"ffle7clDpvWH"}}]}